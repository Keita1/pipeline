{
  "metadata" : {
    "name" : "Cassandra Exercises - Load and Save Movie and Ratings Data",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "customLocalRepo" : "/root/.ivy2",
    "customRepos" : null,
    "customDeps" : [ "com.datastax.spark:spark-cassandra-connector_2.10:1.4.0-M3", "com.databricks:spark-csv_2.10:1.2.0", "- org.apache.spark % spark-core_2.10 % _", "- org.apache.hadoop % _ % _" ],
    "customImports" : null,
    "customSparkConf" : {
      "spark.cassandra.connection.host" : "127.0.0.1",
      "spark.master" : "spark://127.0.0.1:7077",
      "spark.executor.cores" : "2",
      "spark.executor.memory" : "512m",
      "spark.cores.max" : "2",
      "spark.eventLog.enabled" : "true",
      "spark.eventLog.dir" : "logs/spark"
    }
  },
  "cells" : [ {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Setup the SQL Context and necessary imports"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val sqlContext = new org.apache.spark.sql.SQLContext(sparkContext)\nimport sqlContext.implicits._\nimport org.apache.spark.sql.functions._",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Exercise 1 - Load the movies from cvs and save to Cassandra\n### Load the Movies dataset as Data Frames"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val moviesFromCSV = sqlContext.read.format(\"com.databricks.spark.csv\")\n                        .option(\"header\", \"true\")\n                        .load(\"file:/root/pipeline/datasets/ml-latest-small/movies.csv\")\n                        .toDF(\"movieid\", \"title\", \"genres\")",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : ":markdown\nThere are **${moviesFromCSV.count}** ratings",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Save the Data Frame to Cassandra\n\nCreate the necessary CQL schema\n\n* In a terminal window go to cqlsh\n* Change to use the pipeline schema --> use pipeline;\n* Create the schema for movies by ratings  -->  CREATE TABLE movies (movieId int, title text, genres text, PRIMARY KEY(movieId));\n\n"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import com.datastax.spark.connector.cql.CassandraConnector\n\nCassandraConnector(sparkContext.getConf).withSessionDo { session =>\n  session.execute(\"CREATE TABLE pipeline.movies (movieId int, title text, genres text, PRIMARY KEY(movieId));\")\n  session.execute(\"CREATE TABLE pipeline.movies_by_ratings (avg_rating float, max_rating float, movieId int, genres text, title text, PRIMARY KEY(movieId));\")\n}",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.sql.SaveMode\n\nmoviesFromCSV.write.format(\"org.apache.spark.sql.cassandra\")\n          .mode(SaveMode.Append)\n          .options(Map(\"keyspace\" -> \"pipeline\", \"table\" -> \"movies\"))\n          .save()",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "Verify the data was inserted in Cassandra\n* cqlsh\n* use pipeline;\n* select * from movies where movieid = 19;"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Exercise 2 - Load the movies and rating data \n### Load the ratings data from csv\n\nRename the column movieId so that it doesn't conflict after joining with movie data"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.sql.functions._\nval ratingDF = sqlContext.read.format(\"com.databricks.spark.csv\")\n                    .option(\"header\", \"true\")\n                    .load(\"file:/root/pipeline/datasets/ml-latest-small/ratings.csv\")\n                    .withColumnRenamed(\"movieId\",\"ratingMovieId\")",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.sql.functions._\nratingDF: org.apache.spark.sql.DataFrame = [userId: string, ratingMovieId: string, rating: string, timestamp: string]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anonb3cc7859ba64857667fbcb7a9720a6db&quot;,&quot;partitionIndexId&quot;:&quot;anona117fdcf70e19bd2bf93c25644e0d21d&quot;,&quot;numPartitions&quot;:4010,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;userId&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;ratingMovieId&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;rating&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;timestamp&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 71
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Load the movie data from Cassandra"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val moviesDF = sqlContext.read.format(\"org.apache.spark.sql.cassandra\")\n                    .options(Map( \"keyspace\" -> \"pipeline\", \"table\" -> \"movies\"))\n                    .load()",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "moviesDF: org.apache.spark.sql.DataFrame = [movieid: int, genres: string, title: string]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon93b28491c7e83588349181beb5b8c2fc&quot;,&quot;partitionIndexId&quot;:&quot;anon37f6f91434d048fbaf15f4aba70525d4&quot;,&quot;numPartitions&quot;:358,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;movieid&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;genres&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;title&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 25
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val movieAndRatingsDF = moviesDF.join(ratingsDF, ratingsDF(\"ratingMovieId\") === moviesDF(\"movieid\"))\n                                .drop(\"ratingMovieId\")\n                                  .rdd\n                                  .groupBy(row => row.getAs[Int](\"movieid\"))\n                                    .mapValues(_.map(_.getAs[String](\"rating\")).toList.map(_.toDouble))\n                                    .toDF(\"movieid\", \"ratings\")\n()",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "movieAndRatingsDF: org.apache.spark.sql.DataFrame = [movieid: int, ratings: array<double>]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 72
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "movieAndRatingsDF.take(20).toList.map(_.getAs[List[Double]](\"ratings\"))",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res50: List[List[Double]] = List(List(3.0, 3.0), List(3.0, 4.0, 5.0, 5.0, 3.0, 5.0, 4.0, 5.0, 5.0, 5.0, 2.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.5, 4.0, 3.0, 4.0, 5.0, 3.0, 4.0, 5.0, 4.0, 2.0), List(4.0), List(4.0), List(4.0), List(5.0), List(3.5), List(3.0), List(3.0, 4.0, 4.0, 3.0, 4.0, 5.0, 4.0, 4.0), List(3.0), List(3.5), List(3.5), List(1.5, 4.5), List(4.0, 4.0), List(1.5, 0.5, 2.0), List(4.0, 3.0, 3.5, 3.0, 3.5, 4.5, 4.0), List(2.0), List(5.0), List(4.0, 3.0, 4.0, 2.0, 5.0, 3.5, 3.0, 4.0, 3.5, 3.5, 3.0, 4.0, 4.5), List(4.0))\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"container-fluid\"><div><div class=\"col-md-12\"><div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon66f452d8722daaf1a80923a8d5c915d3&quot;,&quot;dataInit&quot;:[{&quot;tl&quot;:&quot;List(3.0)&quot;},{&quot;tl&quot;:&quot;List(4.0, 5.0, 5.0, 3.0, 5.0, 4.0, 5.0, 5.0, 5.0, 2.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.5, 4.0, 3.0, 4.0, 5.0, 3.0, 4.0, 5.0, 4.0, 2.0)&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List(4.0, 4.0, 3.0, 4.0, 5.0, 4.0, 4.0)&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List(4.5)&quot;},{&quot;tl&quot;:&quot;List(4.0)&quot;},{&quot;tl&quot;:&quot;List(0.5, 2.0)&quot;},{&quot;tl&quot;:&quot;List(3.0, 3.5, 3.0, 3.5, 4.5, 4.0)&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List()&quot;},{&quot;tl&quot;:&quot;List(3.0, 4.0, 2.0, 5.0, 3.5, 3.0, 4.0, 3.5, 3.5, 3.0, 4.0, 4.5)&quot;},{&quot;tl&quot;:&quot;List()&quot;}],&quot;genId&quot;:&quot;309118897&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[\"tl\"],\"nrow\":20,\"shown\":20,\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div></div></div></div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 74
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Calculate the Average Ratings for each Movie"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val movieRatingAvgMax = ratingsDF.groupBy(ratingsDF(\"ratingMovieId\"))\n                          .agg(avg($\"rating\"), max($\"rating\"))\n                          .toDF(\"ratingMovieId\", \"avg_rating\", \"max_rating\")",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Join the Movie Ratings Averages and Maxs with the Details of the Movie"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val joinedMovieRatingDF = movieRatingAvgMax\n            .join(moviesDF, movieRatingAvgMax(\"ratingMovieId\") === moviesDF(\"movieid\"))\n            .drop(\"ratingMovieId\")",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "joinedMovieRatingDF: org.apache.spark.sql.DataFrame = [avg_rating: double, max_rating: string, movieid: int, genres: string, title: string]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anonbdd64d897ebc4ba8b9d23028b39e8c66&quot;,&quot;partitionIndexId&quot;:&quot;anona2fb511d2448466ad3ab3288ae8c17d1&quot;,&quot;numPartitions&quot;:357,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;avg_rating&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;max_rating&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;movieid&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;genres&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;title&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 23
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Save the Data Frame to Cassandra\n\n* Create the necessary CQL schema - in a terminal window go to cqlsh\n* Change to use the pipeline schema --> use pipeline;\n* Create the schema for movies by ratings  -->  CREATE TABLE movies_by_ratings (avg_rating float, max_rating float, movieId int, genres text, title text, PRIMARY KEY(movieId));\"\n"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "joinedMovieRatingDF.write.format(\"org.apache.spark.sql.cassandra\")\n          .mode(SaveMode.Append)\n          .options(Map(\"keyspace\" -> \"pipeline\", \"table\" -> \"movies_by_ratings\"))\n          .save()",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "###Pushing Queries Down to Cassandra"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "moviesDF.explain",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val moviesDF3 = sqlContext.read.format(\"org.apache.spark.sql.cassandra\")\n                    .options(Map( \"keyspace\" -> \"pipeline\", \"table\" -> \"movies\"))\n                    .load()\n\nval filteredMovies = moviesDF3.filter(moviesDF3(\"movieid\") > 8000)",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "output_stream_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "filteredMovies.explain",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : true,
      "output_stream_collapsed" : true,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : ":markdown\nThere are\n* **${moviesDF.count}** movies before filtering and\n* **${filteredMovies.count}** movies after filtering",
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}